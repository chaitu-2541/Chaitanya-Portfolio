<!-- Experience Section -->
<section class="experience section" id="experience">
    <div class="container">
        <div class="section-heading">
            <h2>Experience</h2>
            <div class="underline"></div>
        </div>
        <div class="experience-timeline">
            <!-- Experience Item 1: Software Engineer -->
            <div class="timeline-item">
                <div class="timeline-icon">
                    <i class="fas fa-briefcase"></i> <!-- Example icon -->
                </div>
                <div class="timeline-content">
                    <div class="timeline-header">
                        <img src="assets/images/company-logo-epam.png" alt="EPAM Systems" class="company-logo">
                        <div class="company-info">
                            <h3 class="job-title">Data Engineer</h3>
                            <h4 class="company-name">EPAM Systems</h4>
                            <span class="job-duration"><i class="far fa-calendar-alt"></i> Nov 2022 - Aug 2024</span>
                            <p class="company-location"><i class="fas fa-map-marker-alt"></i> Telangana, India</p>
                        </div>
                    </div>
                    <div class="job-description">
                        <ul>
                            <li>Enhanced system performance by identifying and resolving infrastructure bottlenecks, improving responsiveness by 38% and ensuring seamless interaction between front-end user interfaces and backend systems.</li>
                            <li>Developed and optimized real-time ETL pipelines across Snowflake, Azure Data Lake, and AWS S3, increasing data flow efficiency by 57% and processing speed by 35% through effective data ingestion, transformation, and architecture improvements.</li>
                            <li>Designed scalable data workflows leveraging Azure Data Factory and Azure Functions, implementing metadata-driven triggers that reduced batch latency by 42% and enhanced cross-platform data integration accuracy by 33%.</li>
                            <li>Automated analytics workflows using PySpark and Foundry dashboards, decreasing manual effort by 84% and delivering real-time business insights that improved decision-making effectiveness by 52%.</li>
                            <li>Collaborated with cross-functional teams to analyze business requirements, apply data visualization and modeling techniques, and ensure data consistency across cloud data platforms (AWS, Azure, Snowflake).</li>
                            <li>Conducted root cause analysis on ETL process failures and implemented 10+ changes that reduced recurrences by 38%.</li>
                        </ul>
                        <!-- modify tech stack  , company logo-->
                    </div>


                    <div class="experience-tech-stack">
                        <h5>Tech Stack:</h5>
                        <div class="tech-tags">
                            <span class="tech-tag">SQL</span>
                            <span class="tech-tag">PySpark</span>
                            <span class="tech-tag">AWS S3</span>
                            <span class="tech-tag">Azure Data Factory</span>
                            <span class="tech-tag">Azure Databricks</span>
                            <span class="tech-tag">Azure Functions</span>
                            <span class="tech-tag">Snowflake</span>
                            <span class="tech-tag">Airflow</span>
                            <span class="tech-tag">Palantir Foundry</span>
                            <span class="tech-tag">Power BI</span>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Experience Item 2: Software Development Internship -->
            <div class="timeline-item">
                <div class="timeline-icon">
                    <i class="fas fa-graduation-cap"></i> <!-- Example icon for internship -->
                </div>
                <div class="timeline-content">
                    <div class="timeline-header">
                        <img src="assets/images/company-logo-epam.png" alt="EPAM Systems" class="company-logo">
                        <div class="company-info">
                            <h3 class="job-title">Data Engineer Intern</h3>
                            <h4 class="company-name">EPAM Systems</h4>
                            <span class="job-duration"><i class="far fa-calendar-alt"></i> Jan 2022 - Oct 2022</span>
                            <p class="company-location"><i class="fas fa-map-marker-alt"></i> Telangana, India</p>
                        </div>
                    </div>
                    <div class="job-description">
                        <ul>
                            <li>Configured and managed Azure Data Lake Storage Gen2, designing scalable data storage solutions across 15+ storage accounts and processing 500+ CSV datasets, ensuring efficient data ingestion and accessibility for analytics.</li>
                            <li>Engineered and refined end-to-end data pipelines using Azure Databricks, Python (Pandas), and SQL, transforming large datasets into Parquet format for Snowflake integration, which improved data processing speed by 63% and enhanced data architecture efficiency.</li>
                            <li>Analyzed and interpreted large data sets through Python and SQL, uncovering key insights that informed strategic business decisions, leading to a 25% improvement in decision accuracy and operational efficiency.</li>
                            <li>Built and maintained a robust data warehouse structure, streamlining data integration and reducing retrieval time by 20%, while improving data quality and validation accuracy across systems.</li>
                            <li>Designed and automated Power BI dashboards and reports, providing real-time data visualization and saving 10+ team hours per week, improving visibility into business performance metrics.</li>
                            <li>Collaborated with cross-functional teams (analysts, data engineers, and business stakeholders) to optimize data processes, increasing team productivity by 15% and ensuring accurate, timely reporting.</li>
                            <li>Optimized SQL queries and ETL processes, reducing execution times by 38% and improving code coverage and performance reliability by 15% across reporting systems.</li>
                            <li>Demonstrated adaptability, accountability, and analytical thinking in a dynamic, cloud-based environment aligning technical outcomes with business objectives and maintaining data integrity throughout the process.</li>
                        </ul>
                    </div>
                    <div class="experience-tech-stack">
                        <h5>Tech Stack:</h5>
                        <div class="tech-tags"> 
                            <span class="tech-tag">SQL</span>
                            <span class="tech-tag">PySpark</span>
                            <span class="tech-tag">ADLS Gen2</span>
                            <span class="tech-tag">Azure SQL Database</span>
                            <span class="tech-tag">Azure Databricks</span>
                            <span class="tech-tag">Snowflake</span>
                        </div>
                    </div>
                </div>
            </div>





           <!-- <div class="timeline-item">
                <div class="timeline-icon">
                    <i class="fas fa-graduation-cap"></i>  
                    //Example icon for internship 
                </div>
                <div class="timeline-content">
                    <div class="timeline-header">
                        <img src="assets/images/company-logo-epam.png" alt="EPAM Systems" class="company-logo">
                        <div class="company-info">
                            <h3 class="job-title">Software Engineer Intern</h3>
                            <h4 class="company-name">EPAM Systems</h4>
                            <span class="job-duration"><i class="far fa-calendar-alt"></i> Jan 2022 - June 2022</span>
                            <p class="company-location"><i class="fas fa-map-marker-alt"></i> Telangana, India</p>
                        </div>
                        
                    </div>
                    <div class="job-description">
                        <ul>
                            <li>Engineered robust applications from scratch using C, Java, NodeJS, and JavaScript, improving system architecture and logical problem-solving without utilizing frameworks.</li>
                            <li>Designed and deployed an online food delivery app on EC2, handling backend architecture, database design, order processing and ensuring a smooth UX from front-end to back-end.</li>
                            <li>Implemented and deployed RESTful web services with Spring Boot, utilizing Spring Data JPA to handle over 6000+ database
                                transactions seamlessly and efficiently.</li>
                            <li>Secured APIs with Spring Security, implementing robust access controls and reducing potential vulnerabilities by 40%.</li>
                            <li>97.8% code coverage achieved through comprehensive unit testing with JUnit and Mockito, ensuring reliability and adherence to test-driven development (TDD) practices.</li>
                        </ul>
                    </div>
                    <div class="experience-tech-stack">
                        <h5>Tech Stack:</h5>
                        <div class="tech-tags">
                            <span class="tech-tag">Java</span>
                            <span class="tech-tag">SQL</span>
                            <span class="tech-tag">Spring Boot</span>
                            <span class="tech-tag">JUnit</span>
                            <span class="tech-tag">Mockito</span>
                        </div>
                    </div>
                </div>
            </div> -->


        </div>
    </div>
</section>
